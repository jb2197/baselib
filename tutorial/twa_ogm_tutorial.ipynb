{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# twa OGM tutorial\n",
    "\n",
    "In this tutorial, we demonstrate basic usage of object graph mapper of the `twa` package.\n",
    "\n",
    "We will go through a few minimal examples with Blazegraph as our triple store and demonstrate how to interact with it through a Python-based SPARQL client.\n",
    "\n",
    "You may skip any of the preparation steps if it's already done.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation 1: Install necessary packages\n",
    "Run this cell to install the necessary Python packages if they are not already installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install twa docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation 2: Setup Docker and SPARQL Client\n",
    "\n",
    "### Start Blazegraph Docker Container\n",
    "Before anything, firstly spin up a Blazegraph container to serve as our triple store.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import docker\n",
    "# Connect to Docker using the default socket or the configuration in your environment:\n",
    "client = docker.from_env()\n",
    "\n",
    "# Run Blazegraph container\n",
    "# It returns a Container object that we will need later for stopping it\n",
    "blazegraph = client.containers.run(\n",
    "    'ghcr.io/cambridge-cares/blazegraph:1.1.0',\n",
    "    ports={'8080/tcp': 27149}, # this binds the internal port 8080/tcp to the external port 27149\n",
    "    detach=True # this runs the container in the background\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and initialize SPARQL Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect to the Blazegraph instance using the SPARQL client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Info: Initializing JPSGateway with resName=JpsBaseLib, jarPath=None\n"
     ]
    }
   ],
   "source": [
    "from twa.kg_operations import PySparqlClient\n",
    "\n",
    "sparql_endpoint = 'http://localhost:27149/blazegraph/namespace/kb/sparql'\n",
    "sparql_client = PySparqlClient(sparql_endpoint, sparql_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql_client.perform_update('delete where { ?s ?p ?o }')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation 3: Importing Libraries\n",
    "\n",
    "Import necessary modules. Note that for a Python script, it is important to include `from __future__ import annotations` at the beginning of the file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from twa.data_model.base_ontology import BaseOntology, BaseClass, ObjectProperty, DatatypeProperty, TransitiveProperty\n",
    "\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Recursive pull and push\n",
    "\n",
    "### Create a ExampleOntology class\n",
    "This class represents the ontology for example purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twa.data_model.base_ontology import KnowledgeGraph\n",
    "KnowledgeGraph.clear_object_lookup()\n",
    "\n",
    "class ExampleOntology(BaseOntology):\n",
    "    base_url = 'https://dummy.example/kg/'\n",
    "    namespace = 'example'\n",
    "    owl_versionInfo = '0.0.1'\n",
    "    rdfs_comment = 'An example ontology'\n",
    "\n",
    "ExampleOntology.set_dev_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Has = ObjectProperty.create_from_base('Has', ExampleOntology)\n",
    "\n",
    "class I(BaseClass):\n",
    "    rdfs_isDefinedBy = ExampleOntology\n",
    "    has: Optional[Has[I]] = set()\n",
    "\n",
    "class I1(I):\n",
    "    pass\n",
    "\n",
    "class I2(I):\n",
    "    pass\n",
    "\n",
    "class I3(I):\n",
    "    pass\n",
    "\n",
    "class I4(I):\n",
    "    pass\n",
    "\n",
    "class I5(I):\n",
    "    pass\n",
    "\n",
    "class I6(I):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the ontology to the triple store\n",
    "ExampleOntology.export_to_triple_store(sparql_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload example triples\n",
    "import rdflib\n",
    "sparql_client.upload_graph(\n",
    "    rdflib.Graph().parse(data=\"\"\"\n",
    "        @prefix : <https://dummy.example/kg/example/> .\n",
    "        :i1 a :I1.\n",
    "        :i2 a :I2.\n",
    "        :i3 a :I3.\n",
    "        :i1 :has :i2, :i3.\n",
    "        \"\"\"\n",
    "    )\n",
    ")\n",
    "# Initially (t = 0), the knowledge graph contains the following triples:\n",
    "#  :i1 a :I1.\n",
    "#  :i2 a :I2.\n",
    "#  :i3 a :I3.\n",
    "#  :i1 :has :i2, :i3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At t = 1, pull the instance :i1 from the graph, retrieving all connected instances recursively:\n",
    "i1 = I1.pull_from_kg(\n",
    "    iris='https://dummy.example/kg/example/i1',\n",
    "    sparql_client=sparql_client,\n",
    "    recursive_depth=-1, # -1 enables full recursion, retrieving all transitive connections\n",
    ")[0] # Results are stored in a list as multiple instances of the same class can be pulled at once if a list of IRIs is passed in for the field `iris`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <https://dummy.example/kg/example/> .\n",
      "\n",
      "ns1:i1 a ns1:I1 ;\n",
      "    ns1:has ns1:i2,\n",
      "        ns1:i3 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(i1.triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At t = 2, an external update is made directly to the knowledge graph via SPARQL:\n",
    "# \"\"\"INSERT DATA { :i4 a :I4 . :i2 :has :i4 . :i3 :has :i4 . }\"\"\"\n",
    "# At this point, the graph contains new triples that are not yet reflected in the Python environment.\n",
    "sparql_client.perform_update(\n",
    "    \"\"\"\n",
    "    PREFIX : <https://dummy.example/kg/example/>\n",
    "    INSERT DATA {\n",
    "        :i4 a :I4 .\n",
    "        :i2 :has :i4 .\n",
    "        :i3 :has :i4 .\n",
    "    }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At t = 2, modify the local Python object by removing the connection between `i1` and `i2`:\n",
    "i1.has.remove('https://dummy.example/kg/example/i2')  # This change is local and not yet propagated to the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At t = 3, push local changes to the graph while first pulling the latest remote state:\n",
    "g_r, g_a = i1.push_to_kg(\n",
    "    sparql_client,\n",
    "    recursive_depth=-1,  # Ensures synchronisation across all transitive links\n",
    "    pull_first=True  # Ensures that any external modifications are pulled before applying local changes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed triples:\n",
      "@prefix ns1: <https://dummy.example/kg/example/> .\n",
      "\n",
      "ns1:i1 ns1:has ns1:i2 .\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Added triples:\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The `g_r` and `g_a` variables contain the graph deletes and the additions, respectively.\n",
    "print('Removed triples:')\n",
    "print(g_r.serialize(format='turtle'))\n",
    "print('---------------------------------')\n",
    "print('Added triples:')\n",
    "print(g_a.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At t = 4, another external update is made to the graph:\n",
    "# \"\"\"INSERT DATA { :i5 a :I5 . :i1 :has :i5 . }\"\"\"\n",
    "# The graph now contains additional data that is not yet present in Python.\n",
    "sparql_client.perform_update(\n",
    "    \"\"\"\n",
    "    PREFIX : <https://dummy.example/kg/example/>\n",
    "    INSERT DATA {\n",
    "        :i5 a :I5 .\n",
    "        :i1 :has :i5 .\n",
    "    }\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At t = 5, create a new instance `i6` locally and establish a relationship with `i1`:\n",
    "i6 = I6()  # A unique IRI is automatically assigned to `i6`\n",
    "i1.has.add(i6)  # This change remains local until explicitly pushed to the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# At t = 6, push the local updates while first pulling any remote changes:\n",
    "g_r, g_a = i1.push_to_kg(\n",
    "    sparql_client,\n",
    "    recursive_depth=-1,  # Ensures full synchronisation\n",
    "    pull_first=True  # External modifications (e.g., `i5`) will be pulled before pushing local changes (e.g., `i6`)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{https://dummy.example/kg/example/I6_e9338ed0-f705-4109-a126-688b16c942df,\n",
       " https://dummy.example/kg/example/i3,\n",
       " https://dummy.example/kg/example/i5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After this operation, the Python environment will contain `i5`, which was previously only in the graph, and the relationship involving `i6` will be pushed to the graph, ensuring full consistency.\n",
    "assert 'https://dummy.example/kg/example/i5' in i1.has\n",
    "i1.has"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed triples:\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Added triples:\n",
      "@prefix ns1: <https://dummy.example/kg/example/> .\n",
      "\n",
      "ns1:i1 ns1:has ns1:I6_e9338ed0-f705-4109-a126-688b16c942df .\n",
      "\n",
      "ns1:I6_e9338ed0-f705-4109-a126-688b16c942df a ns1:I,\n",
      "        ns1:I6 .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can check `g_r` and `g_a` for the exact triples modified when push to remote\n",
    "print('Removed triples:')\n",
    "print(g_r.serialize(format='turtle'))\n",
    "print('---------------------------------')\n",
    "print('Added triples:')\n",
    "print(g_a.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Multi-Inheritance Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from twa.data_model.base_ontology import BaseOntology, BaseClass, ObjectProperty, DatatypeProperty, TransitiveProperty\n",
    "from twa.data_model.iris import TWA_BASE_URL\n",
    "from twa.data_model.base_ontology import KnowledgeGraph\n",
    "\n",
    "\n",
    "KnowledgeGraph.clear_object_lookup()\n",
    "\n",
    "class YourOntology(BaseOntology):\n",
    "    # Below fields can be set up to provide metadata for your ontology\n",
    "    base_url = TWA_BASE_URL\n",
    "    namespace = 'yourontology'\n",
    "    owl_versionInfo = '0.0.1'\n",
    "    rdfs_comment = 'Your ontology'\n",
    "\n",
    "DataB = DatatypeProperty.create_from_base('DataB', YourOntology)\n",
    "DataC = DatatypeProperty.create_from_base('DataC', YourOntology)\n",
    "\n",
    "# Class hierarchy defining multiple inheritance:\n",
    "class T(BaseClass):\n",
    "    rdfs_isDefinedBy = YourOntology\n",
    "\n",
    "class A(T):\n",
    "    rdfs_isDefinedBy = YourOntology\n",
    "\n",
    "class B(A): # Leaf subclass of `A`\n",
    "    data_b: DataB[str]\n",
    "\n",
    "class C(T): # Independent branch from `T`\n",
    "    data_c: DataC[int]\n",
    "\n",
    "class D(C): # Leaf subclass of `C`\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twa.kg_operations import PySparqlClient\n",
    "sparql_endpoint = 'http://localhost:27149/blazegraph/namespace/kb/sparql'\n",
    "sparql_client = PySparqlClient(sparql_endpoint, sparql_endpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparql_client.perform_update('delete where { ?s ?p ?o }') # Clear the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the ontology to the triple store\n",
    "YourOntology.export_to_triple_store(sparql_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Knowledge graph initially contains the following triples for node <i>:\n",
    "#     <i> a <T>, <A>, <B>, <C> .\n",
    "#     <i> :data_c 5 .\n",
    "# i.e. in triple format:\n",
    "# <https://iri_i> a <https://www.theworldavatar.com/kg/yourontology/T>, <https://www.theworldavatar.com/kg/yourontology/A>, <https://www.theworldavatar.com/kg/yourontology/B>, <https://www.theworldavatar.com/kg/yourontology/C> .\n",
    "#    <https://iri_i> <https://www.theworldavatar.com/kg/yourontology/dataC> 5 .\n",
    "# The instance is labelled with multiple types, requiring resolution when pulled into Python.\n",
    "import rdflib\n",
    "sparql_client.upload_graph(\n",
    "    rdflib.Graph().parse(data=\"\"\"\n",
    "        @prefix : <https://www.theworldavatar.com/kg/yourontology/> .\n",
    "        <https://iri_i> a :T, :A, :B, :C .\n",
    "        <https://iri_i> :dataC 5 .\n",
    "        \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull node <i> with class `A`:\n",
    "i = A.pull_from_kg(\n",
    "    'https://iri_i',\n",
    "    sparql_client,\n",
    "    recursive_depth=-1,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since `B` is the most specific subclass within the pulled hierarchy, OGM resolves the instance as `B`:\n",
    "assert type(i) is B\n",
    "assert not i.data_b # No triple exists for `data_b`, so the attribute is empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i.data_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a property relevant to `B` and push changes back to the graph:\n",
    "i.data_b.add(\"my_str\")\n",
    "g_r, g_a = i.push_to_kg(sparql_client, -1)\n",
    "# The following triple is added to the knowledge graph:\n",
    "#     <i> :data_b \"my_str\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed triples:\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Added triples:\n",
      "@prefix ns1: <https://www.theworldavatar.com/kg/yourontology/> .\n",
      "\n",
      "<https://iri_i> ns1:dataB \"my_str\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To view the changes made to the graph, we can check `g_r` and `g_a`:\n",
    "print('Removed triples:')\n",
    "print(g_r.serialize(format='turtle'))\n",
    "print('---------------------------------')\n",
    "print('Added triples:')\n",
    "print(g_a.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now pull node <i> using class `C` instead:\n",
    "i = C.pull_from_kg(\n",
    "    'https://iri_i',\n",
    "    sparql_client,\n",
    "    recursive_depth=-1,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The instance is now instantiated as `C`, and properties specific to `C` are retrieved:\n",
    "assert type(i) is C\n",
    "assert i.data_c == {5} # Retrieved from the knowledge graph\n",
    "\n",
    "# If we create a new instance and push it to the graph:\n",
    "new_i = B(data_b=\"new_str\")\n",
    "g_r, g_a = new_i.push_to_kg(sparql_client, -1)\n",
    "# The following triples are added:\n",
    "#     <new_i> a <B>, <A>, <T> .\n",
    "#     <new_i> :data_b \"new_str\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed triples:\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Added triples:\n",
      "@prefix ns1: <https://www.theworldavatar.com/kg/yourontology/> .\n",
      "\n",
      "ns1:B_85eec40d-d478-4739-8ae1-4ca9b648e9ab a ns1:A,\n",
      "        ns1:B,\n",
      "        ns1:T ;\n",
      "    ns1:dataB \"new_str\" .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To view the changes made to the graph, we can check `g_r` and `g_a`:\n",
    "print('Removed triples:')\n",
    "print(g_r.serialize(format='turtle'))\n",
    "print('---------------------------------')\n",
    "print('Added triples:')\n",
    "print(g_a.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Retrieval of Transitive Property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from twa.data_model.base_ontology import BaseOntology, BaseClass, ObjectProperty, DatatypeProperty, TransitiveProperty\n",
    "from typing import Optional\n",
    "from twa.data_model.base_ontology import KnowledgeGraph\n",
    "\n",
    "\n",
    "KnowledgeGraph.clear_object_lookup()\n",
    "\n",
    "class MyOntology(BaseOntology):\n",
    "    base_url = 'https://example.org/ontology/'\n",
    "    namespace = 'myontology'\n",
    "    owl_versionInfo = '0.0.1'\n",
    "    rdfs_comment = 'My ontology'\n",
    "\n",
    "# We can set the ontology to development mode for testing purposes\n",
    "MyOntology.set_dev_mode()\n",
    "\n",
    "# Define transitive relationships in the knowledge graph using an OGM class structure:\n",
    "Part_of = TransitiveProperty.create_from_base('Part_of', MyOntology)\n",
    "\n",
    "# Define class hierarchies:\n",
    "class Experiment(BaseClass):\n",
    "    rdfs_isDefinedBy = MyOntology\n",
    "\n",
    "class ReactionSetup(BaseClass):\n",
    "    rdfs_isDefinedBy = MyOntology\n",
    "    part_of: Optional[Part_of[Experiment]] = set() # Defines a transitive relationship\n",
    "\n",
    "class Equipment(BaseClass):\n",
    "    rdfs_isDefinedBy = MyOntology\n",
    "    part_of: Optional[Part_of[ReactionSetup]] = set() # Equipment can be part of a reaction setup\n",
    "\n",
    "class EquipmentPart(BaseClass):\n",
    "    rdfs_isDefinedBy = MyOntology\n",
    "    part_of: Optional[Part_of[Equipment]] = set() # Equipment part can be part of an equipment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from twa.kg_operations import PySparqlClient\n",
    "sparql_endpoint = 'http://localhost:27149/blazegraph/namespace/kb/sparql'\n",
    "sparql_client = PySparqlClient(sparql_endpoint, sparql_endpoint)\n",
    "sparql_client.perform_update('delete where { ?s ?p ?o }') # Clear the knowledge graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below triples exist in the knowledge graph:\n",
    "#     :beaker_A a :Equipment .\n",
    "#     :clamp_B a :EquipmentPart .\n",
    "#     :stand_C a :Equipment .\n",
    "#     :reaction_setup_X a :ReactionSetup .\n",
    "#     :experiment_Y a :Experiment .\n",
    "#     :beaker_A :part_of :reaction_setup_X .\n",
    "#     :reaction_setup_X :part_of :experiment_Y .\n",
    "#     :clamp_B :part_of :stand_C .\n",
    "#     :stand_C :part_of :reaction_setup_X .\n",
    "import rdflib\n",
    "sparql_client.upload_graph(\n",
    "    rdflib.Graph().parse(data=\"\"\"\n",
    "        @prefix : <https://example.org/ontology/myontology/> .\n",
    "        :beaker_A a :Equipment .\n",
    "        :clamp_B a :EquipmentPart .\n",
    "        :stand_C a :Equipment .\n",
    "        :reaction_setup_X a :ReactionSetup .\n",
    "        :experiment_Y a :Experiment .\n",
    "        :beaker_A :part_of :reaction_setup_X .\n",
    "        :reaction_setup_X :part_of :experiment_Y .\n",
    "        :clamp_B :part_of :stand_C .\n",
    "        :stand_C :part_of :reaction_setup_X .\n",
    "        \"\"\"\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull node <beaker_A> using class `Equipment`\n",
    "beaker_A = Equipment.pull_from_kg(\n",
    "    'https://example.org/ontology/myontology/beaker_A',\n",
    "    sparql_client,\n",
    "    recursive_depth=-1,  # Fully traverse transitive properties\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we access `beaker_A.part_of` in normal way, we will only get the direct parent\n",
    "assert beaker_A.part_of == {'https://example.org/ontology/myontology/reaction_setup_X'}\n",
    "\n",
    "# If we access `beaker_A.part_of` using the transitive property, we will get all ancestors\n",
    "assert Part_of.obtain_transitive_objects(beaker_A) == {\n",
    "    'https://example.org/ontology/myontology/reaction_setup_X',\n",
    "    'https://example.org/ontology/myontology/experiment_Y'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, pull node <clamp_B> and verify the inferred hierarchy\n",
    "clamp_B = EquipmentPart.pull_from_kg(\n",
    "    'https://example.org/ontology/myontology/clamp_B',\n",
    "    sparql_client,\n",
    "    recursive_depth=-1,\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we access the transitive property in the normal way, `clamp_B` as part of `stand_C`\n",
    "assert clamp_B.part_of == {'https://example.org/ontology/myontology/stand_C'}\n",
    "# If we access `clamp_B` using the transitive property, we will get all ancestors\n",
    "assert Part_of.obtain_transitive_objects(clamp_B) == {\n",
    "    'https://example.org/ontology/myontology/stand_C',\n",
    "    'https://example.org/ontology/myontology/reaction_setup_X',\n",
    "    'https://example.org/ontology/myontology/experiment_Y'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we add a new equipment relationship and push it to the knowledge graph:\n",
    "new_equipment = Equipment()\n",
    "new_equipment.part_of.add('https://example.org/ontology/myontology/reaction_setup_X')\n",
    "g_r, g_a = new_equipment.push_to_kg(sparql_client, -1)\n",
    "\n",
    "# Below triple will be added:\n",
    "#     :new_equipment a :Equipment .\n",
    "#     :new_equipment :part_of :reaction_setup_X ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed triples:\n",
      "\n",
      "\n",
      "---------------------------------\n",
      "Added triples:\n",
      "@prefix ns1: <https://example.org/ontology/myontology/> .\n",
      "\n",
      "ns1:Equipment_0f12f5c5-b326-44ad-a594-b859a17d744f a ns1:Equipment ;\n",
      "    ns1:part_of ns1:reaction_setup_X .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# To view the changes made to the graph, we can check `g_r` and `g_a`:\n",
    "print('Removed triples:')\n",
    "print(g_r.serialize(format='turtle'))\n",
    "print('---------------------------------')\n",
    "print('Added triples:')\n",
    "print(g_a.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 4: Load Nested JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we reuse the ontology and classes defined above in Example 1\n",
    "# Below concepts are re-defined so that you can run this example independently\n",
    "from __future__ import annotations\n",
    "from twa.data_model.base_ontology import BaseOntology, BaseClass, ObjectProperty, DatatypeProperty, TransitiveProperty\n",
    "from typing import Optional\n",
    "from twa.data_model.base_ontology import KnowledgeGraph\n",
    "\n",
    "\n",
    "KnowledgeGraph.clear_object_lookup()\n",
    "\n",
    "class ExampleOntology(BaseOntology):\n",
    "    base_url = 'https://dummy.example/kg/'\n",
    "    namespace = 'example'\n",
    "    owl_versionInfo = '0.0.1'\n",
    "    rdfs_comment = 'An example ontology'\n",
    "\n",
    "ExampleOntology.set_dev_mode()\n",
    "\n",
    "Has = ObjectProperty.create_from_base('Has', ExampleOntology)\n",
    "\n",
    "class I(BaseClass):\n",
    "    rdfs_isDefinedBy = ExampleOntology\n",
    "    has: Optional[Has[I]] = set()\n",
    "\n",
    "class I1(I):\n",
    "    pass\n",
    "\n",
    "class I2(I):\n",
    "    pass\n",
    "\n",
    "class I3(I):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we also define a lean Pydantic model to represent the same data structure\n",
    "from pydantic import BaseModel, Field\n",
    "class IModel(BaseModel):\n",
    "    instance_iri: str\n",
    "    has: Optional[list[IModel]] = Field(default_factory=list)\n",
    "\n",
    "class I1Model(IModel):\n",
    "    pass\n",
    "\n",
    "class I2Model(IModel):\n",
    "    pass\n",
    "\n",
    "class I3Model(IModel):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define the nested JSON to be loaded\n",
    "import json\n",
    "json_data = {\n",
    "  'instance_iri': 'https://dummy.example/kg/example/I1_6e3af415',\n",
    "  'has': [\n",
    "    {\n",
    "      'instance_iri': 'https://dummy.example/kg/example/I2_c3a0238f',\n",
    "      'has': [\n",
    "        {\n",
    "          'instance_iri': 'https://dummy.example/kg/example/I3_7b53f45c',\n",
    "          'has': []\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      'instance_iri': 'https://dummy.example/kg/example/I3_7b53f45c',\n",
    "      'has': []\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data into the OGM and Pydantic models\n",
    "ogm_loaded_i1 = I1.model_validate_json(json.dumps(json_data))\n",
    "pydantic_loaded_i1 = I1Model.model_validate_json(json.dumps(json_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can check the loaded data\n",
    "assert ogm_loaded_i1.has == {\n",
    "    'https://dummy.example/kg/example/I2_c3a0238f',\n",
    "    'https://dummy.example/kg/example/I3_7b53f45c'\n",
    "}\n",
    "ogm_loaded_i2 = KnowledgeGraph.get_object_from_lookup('https://dummy.example/kg/example/I2_c3a0238f')\n",
    "assert ogm_loaded_i2.has == {\n",
    "    'https://dummy.example/kg/example/I3_7b53f45c'\n",
    "}\n",
    "ogm_loaded_i3 = KnowledgeGraph.get_object_from_lookup('https://dummy.example/kg/example/I3_7b53f45c')\n",
    "assert ogm_loaded_i3.has == set()\n",
    "# NOTE importantly, we need to check the id of the i3 pointed by i2 has the same id as the one in the loaded i3\n",
    "assert id(ogm_loaded_i3) == id(list(ogm_loaded_i2.has)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<https://dummy.example/kg/example/I3_7b53f45c> a <https://dummy.example/kg/example/I> .\n",
      "\n",
      "\n",
      "@prefix ns1: <https://dummy.example/kg/example/> .\n",
      "\n",
      "ns1:I2_c3a0238f a ns1:I ;\n",
      "    ns1:has ns1:I3_7b53f45c .\n",
      "\n",
      "\n",
      "@prefix ns1: <https://dummy.example/kg/example/> .\n",
      "\n",
      "ns1:I1_6e3af415 a ns1:I1 ;\n",
      "    ns1:has ns1:I2_c3a0238f,\n",
      "        ns1:I3_7b53f45c .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can also check the triples\n",
    "for o in KnowledgeGraph.construct_object_lookup().values():\n",
    "    print(o.triples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://dummy.example/kg/example/I3_7b53f45c\n",
      "https://dummy.example/kg/example/I3_7b53f45c\n"
     ]
    }
   ],
   "source": [
    "# For data loaded in the Pydantic model, we will see that even though two objects share the same IRI, they are different objects in memory\n",
    "pydantic_loaded_i2 = pydantic_loaded_i1.has[0]\n",
    "pydantic_loaded_i3 = pydantic_loaded_i1.has[1]\n",
    "print(pydantic_loaded_i2.has[0].instance_iri)\n",
    "print(pydantic_loaded_i3.instance_iri)\n",
    "assert pydantic_loaded_i2.has[0].instance_iri == pydantic_loaded_i3.instance_iri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831727524160 1831728404176\n"
     ]
    }
   ],
   "source": [
    "# But they are not the same object in memory\n",
    "print(id(pydantic_loaded_i2.has[0]), id(pydantic_loaded_i3))\n",
    "assert id(pydantic_loaded_i2.has[0]) != id(pydantic_loaded_i3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 5: Find Ontological Concepts/Relationships in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we reuse the ontology and classes defined above in Example 1\n",
    "# Below concepts are re-defined so that you can run this example independently\n",
    "from __future__ import annotations\n",
    "from twa.data_model.base_ontology import BaseOntology, BaseClass, ObjectProperty, DatatypeProperty, TransitiveProperty\n",
    "from typing import Optional\n",
    "from twa.data_model.base_ontology import KnowledgeGraph\n",
    "\n",
    "\n",
    "KnowledgeGraph.clear_object_lookup()\n",
    "\n",
    "class ExampleOntology(BaseOntology):\n",
    "    base_url = 'https://dummy.example/kg/'\n",
    "    namespace = 'example'\n",
    "    owl_versionInfo = '0.0.1'\n",
    "    rdfs_comment = 'An example ontology'\n",
    "\n",
    "ExampleOntology.set_dev_mode()\n",
    "\n",
    "Has = ObjectProperty.create_from_base('Has', ExampleOntology)\n",
    "\n",
    "class I(BaseClass):\n",
    "    rdfs_isDefinedBy = ExampleOntology\n",
    "    has: Optional[Has[I]] = set()\n",
    "\n",
    "class I1(I):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dummy.example/kg/example/I1'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assume that we have already defined the ontology and classes as in Example 1\n",
    "# To know the IRI of a class\n",
    "I1.rdf_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.I1"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the python class from the IRI, we can use the `class_lookup` dictionary\n",
    "KnowledgeGraph.class_lookup['https://dummy.example/kg/example/I1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'https://dummy.example/kg/example/This_Does_Not_Exist'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mKnowledgeGraph\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclass_lookup\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhttps://dummy.example/kg/example/This_Does_Not_Exist\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;66;03m# This will raise a KeyError\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'https://dummy.example/kg/example/This_Does_Not_Exist'"
     ]
    }
   ],
   "source": [
    "KnowledgeGraph.class_lookup['https://dummy.example/kg/example/This_Does_Not_Exist'] # This will raise a KeyError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final clean up\n",
    "### Stop Blazegraph Docker Container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "blazegraph.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If one wish to remove the blazegraph container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "blazegraph.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author\n",
    "Jiaru Bai (jb2197@cantab.ac.uk)\n",
    "\n",
    "## Citation\n",
    "\n",
    "If you found this tool useful, please consider citing the following preprint:\n",
    "\n",
    "```bibtex\n",
    "@article{bai2025twa,\n",
    "  title={{twa: The World Avatar Python package for dynamic knowledge graphs and its application in reticular chemistry}},\n",
    "  author={Bai, Jiaru and Rihm, Simon D and Kondinski, Aleksandar and Saluz, Fabio and Deng, Xinhong and Brownbridge, George and Mosbach, Sebastian and Akroyd, Jethro and Kraft, Markus},\n",
    "  year={2025},\n",
    "  note={Preprint at \\url{https://como.ceb.cam.ac.uk/preprints/335/}}\n",
    "}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
